{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "VMAS: Use vmas environment.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "0NsC_EwfCF5I"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "id": "0NsC_EwfCF5I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP9ijqwvIXGd",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "! git clone https://github.com/proroklab/VectorizedMultiAgentSimulator.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "%cd /content/VectorizedMultiAgentSimulator\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "!apt-get update\n",
    "!apt-get install -y x11-utils \n",
    "!apt-get install -y xvfb\n",
    "!apt-get install -y imagemagick\n",
    "!pip install -e ."
   ],
   "metadata": {
    "id": "zjnXLxaOMLuv",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "!pip install pyvirtualdisplay\n",
    "import pyvirtualdisplay\n",
    "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "display.start()"
   ],
   "metadata": {
    "id": "5wilTW60cNr4",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run\n"
   ],
   "metadata": {
    "id": "jAAA3DXGCLkF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#  Copyright (c) 2022.\n",
    "#  ProrokLab (https://www.proroklab.org/)\n",
    "#  All rights reserved.\n",
    "\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from vmas import make_env\n",
    "\n",
    "scenario_name = \"waterfall\"\n",
    "\n",
    "# Scenario specific variables\n",
    "n_agents = 4\n",
    "\n",
    "num_envs = 32  # Number of vectorized environments\n",
    "continuous_actions = False\n",
    "device = \"cpu\"  # or cuda or any other torch device\n",
    "n_steps = 100  # Number of steps before returning done\n",
    "dict_spaces = True  # Weather to return obs, rewards, and infos as dictionaries with agent names (by default they are lists of len # of agents)\n",
    "\n",
    "simple_2d_action = (\n",
    "    [0, 0.5] if continuous_actions else [3]\n",
    ")  # Simple action tell each agent to go down\n",
    "\n",
    "env = make_env(\n",
    "    scenario=scenario_name,\n",
    "    num_envs=num_envs,\n",
    "    device=device,\n",
    "    continuous_actions=continuous_actions,\n",
    "    dict_spaces=dict_spaces,\n",
    "    wrapper=None,\n",
    "    seed=None,\n",
    "    # Environment specific variables\n",
    "    n_agents=n_agents,\n",
    ")\n",
    "\n",
    "frame_list = []  # For creating a gif\n",
    "init_time = time.time()\n",
    "step = 0\n",
    "\n",
    "for s in range(n_steps):\n",
    "    step += 1\n",
    "    print(f\"Step {step}\")\n",
    "\n",
    "    # VMAS actions can be either a list of tensors (one per agent)\n",
    "    # or a dict of tensors (one entry per agent with its name as key)\n",
    "    # Both action inputs can be used independently of what type of space its chosen\n",
    "    dict_actions = random.choice([True, False])\n",
    "\n",
    "    actions = {} if dict_actions else []\n",
    "    for i, agent in enumerate(env.agents):\n",
    "        action = torch.tensor(\n",
    "            simple_2d_action,\n",
    "            device=device,\n",
    "        ).repeat(num_envs, 1)\n",
    "        if dict_actions:\n",
    "            actions.update({agent.name: action})\n",
    "        else:\n",
    "            actions.append(action)\n",
    "\n",
    "    obs, rews, dones, info = env.step(actions)\n",
    "\n",
    "    frame_list.append(\n",
    "        Image.fromarray(env.render(mode=\"rgb_array\", agent_index_focus=None))\n",
    "    )  # Can give the camera an agent index to focus on\n",
    "\n",
    "gif_name = scenario_name + \".gif\"\n",
    "\n",
    "# Produce a gif\n",
    "frame_list[0].save(\n",
    "    gif_name,\n",
    "    save_all=True,\n",
    "    append_images=frame_list[1:],\n",
    "    duration=3,\n",
    "    loop=0,\n",
    ")\n",
    "\n",
    "\n",
    "total_time = time.time() - init_time\n",
    "print(\n",
    "    f\"It took: {total_time}s for {n_steps} steps of {num_envs} parallel environments on device {device} \"\n",
    "    f\"for {scenario_name} scenario.\"\n",
    ")"
   ],
   "metadata": {
    "id": "2Ol4AFeRQ3Ma"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(open(f'{scenario_name}.gif','rb').read())"
   ],
   "metadata": {
    "id": "UPRa91hMPU1n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "# Requires imagemagick to be installed to convert the gif in faster format\n",
    "os.system(f\"convert -delay 1x30 -loop 0 {gif_name} {scenario_name}_fast.gif\")\n",
    "from IPython.display import Image\n",
    "Image(open(f'{scenario_name}_fast.gif','rb').read())"
   ],
   "metadata": {
    "id": "BohliLebMOJB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
